{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-ribbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, Input, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, AveragePooling2D\n",
    "from tensorflow.keras.layers import Reshape, Conv2DTranspose, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.cluster import KMeans\n",
    "from skimage.color import rgb2hsv, rgb2lab\n",
    "from minisom import MiniSom\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from collections import defaultdict, Counter\n",
    "from pylab import pcolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-attribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024 * 8.5)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-giving",
   "metadata": {},
   "source": [
    "## Pet Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-offense",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "pet_dir = './pet_images/'\n",
    "\n",
    "pets_df = pd.DataFrame(columns=['img', 'img_mask'])\n",
    "\n",
    "k = 0\n",
    "# load image data\n",
    "for filename in sorted(os.listdir(pet_dir)):\n",
    "    if filename.endswith('.jpg'):\n",
    "        pets_df.loc[k, 'img'] = np.asarray(Image.open(pet_dir + filename).resize((160, 240)))\n",
    "    else:\n",
    "        continue\n",
    "    k = k+1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-expert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "pet_dir1 = './trimaps/'\n",
    "\n",
    "k = 0\n",
    "# load ground truth data\n",
    "for filename in sorted(os.listdir(pet_dir1)):\n",
    "    if filename.startswith('._'):\n",
    "        continue  \n",
    "    elif filename.endswith(\".png\"):\n",
    "        pets_df.loc[k, 'img_mask'] = np.asarray(Image.open(pet_dir1 + filename).resize((160, 240)))\n",
    "    else:\n",
    "        continue\n",
    "    k = k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-redhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "pets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-florence",
   "metadata": {},
   "outputs": [],
   "source": [
    "pet, mask = pets_df['img'].to_numpy(), pets_df['img_mask'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all images have same shape\n",
    "for i in range(pet.shape[0]):\n",
    "    if pet[i].shape != (240, 160, 3):\n",
    "        print(i, pet[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-transformation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove images with wrong shape\n",
    "pet = np.delete(pet, (136, 148, 1033, 1042, 1043, 1049, 1070, 1079, 1089, 1095, 6899, 6905), axis=0)\n",
    "mask = np.delete(mask, (136, 148, 1033, 1042, 1043, 1049, 1070, 1079, 1089, 1095, 6899, 6905), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data in right format and normalize\n",
    "f = []\n",
    "for i in pet:\n",
    "    f.append(i)\n",
    "pet_feats = np.asarray(f)\n",
    "pet_feats = np.reshape(pet_feats, [-1, 240, 160, 3])\n",
    "pet_feats = pet_feats.astype('float32') / 255\n",
    "pet_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-harvey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get random image function\n",
    "def get_rand_images(original, others):\n",
    "    \n",
    "    idx = np.random.randint(0, original.shape[0], 8)\n",
    "    images = []\n",
    "    for ind in idx:\n",
    "        images.append(original[ind])\n",
    "        images.append(others[ind])\n",
    "    plt.figure(figsize=(64, 64))\n",
    "    num_images = 16\n",
    "    rows = 4\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(rows+1, rows+1, i+1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.axis('off')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-rugby",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original and ground truth mask\n",
    "get_rand_images(pet_feats, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-royalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save pets dataset as numpy array\n",
    "\n",
    "np.save('pets', pet_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-socket",
   "metadata": {},
   "source": [
    "# KMeans Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-reaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment out if data loaded\n",
    "pets = np.load('pets.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-conversation",
   "metadata": {},
   "outputs": [],
   "source": [
    "pets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get hsv and lab conversions for data\n",
    "hsv = np.zeros((7378, 240, 160, 3))\n",
    "lab = np.zeros((7378, 240, 160, 3))\n",
    "\n",
    "for i in range(pets.shape[0]):\n",
    "    hsv[i] = rgb2hsv(pets[i])\n",
    "    lab[i] = rgb2lab(pets[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-bruce",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(0, pets.shape[0], 8)\n",
    "images = []\n",
    "for ind in idx:\n",
    "    images.append(pets[ind])\n",
    "    images.append(hsv[ind])\n",
    "    images.append(lab[ind])\n",
    "plt.figure(figsize=(64, 64))\n",
    "num_images = 16\n",
    "rows = 4\n",
    "for i in range(num_images):\n",
    "    plt.subplot(rows+1, rows+1, i+1)\n",
    "    plt.imshow(images[i])\n",
    "    plt.axis('off')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-links",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all data in one array\n",
    "z = np.zeros((7378, 240, 160, 9))\n",
    "\n",
    "for i in range(z.shape[0]):\n",
    "    z[i] = np.dstack((pet_feats[i], hsv[i], lab[i]))\n",
    "\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-wireless",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape\n",
    "z = np.reshape(z, [7378, 38400, 9])\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-geography",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run kmeans\n",
    "labels = np.zeros((7378, 38400))\n",
    "kmeans = KMeans(random_state=42, init='k-means++', n_init=10, n_clusters=2, max_iter=1000)\n",
    "for i in range(z.shape[0]):\n",
    "    labels[i] = kmeans.fit_predict(z[i])\n",
    "    if i % 500 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-county",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape kmeans output \n",
    "labels = np.reshape(labels, [-1, 240, 160])\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save kmeans mask images in numpy array\n",
    "\n",
    "np.save('pets_kmeans1', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "known-saint",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rand_images(pets, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-relay",
   "metadata": {},
   "source": [
    "## Autoencoder and Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-highlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_feats = np.load('pets.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-johnston",
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_feats = np.reshape(pet_feats, [-1, 240, 160, 3])\n",
    "pet_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-calibration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network parameters\n",
    "input_shape = (240, 160, 3)\n",
    "batch_size = 16\n",
    "kernel_size = 9\n",
    "latent_dim = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-administration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder/decoder number of CNN layers and filters per layer\n",
    "layer_filters = [64, 128, 256, 512]\n",
    "\n",
    "# first build the encoder model\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = inputs\n",
    "for filters in layer_filters:\n",
    "    x = Conv2D(filters=filters,\n",
    "               kernel_size=kernel_size,\n",
    "               activation='relu',\n",
    "               kernel_initializer = 'he_normal',\n",
    "               strides=1,\n",
    "               padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "shape = K.int_shape(x)\n",
    "\n",
    "# generate latent vector\n",
    "x = Flatten()(x)\n",
    "latent = Dense(latent_dim, name='latent_vector')(x)\n",
    "\n",
    "# instantiate encoder model\n",
    "encoder = Model(inputs,\n",
    "                latent,\n",
    "                name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-mixture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the decoder model\n",
    "latent_inputs = Input(shape=(latent_dim,), name='decoder_input')\n",
    "\n",
    "x = Dense(shape[1] * shape[2] * shape[3])(latent_inputs)\n",
    "x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
    "\n",
    "# stack of Conv2DTranspose(64)-Conv2DTranspose(32)\n",
    "for filters in layer_filters[::-1]:\n",
    "    x = Conv2DTranspose(filters=filters,\n",
    "                        kernel_size=kernel_size,\n",
    "                        activation='relu',\n",
    "                        kernel_initializer = 'he_normal',\n",
    "                        strides=2,\n",
    "                        padding='same')(x)\n",
    "\n",
    "# reconstruct the input\n",
    "outputs = Conv2DTranspose(filters=3,\n",
    "                          kernel_size=1,\n",
    "                          activation='sigmoid',\n",
    "                          padding='same',\n",
    "                          kernel_initializer = 'he_normal',\n",
    "                          name='decoder_output')(x)\n",
    "\n",
    "# instantiate decoder model\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-bidding",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# autoencoder = encoder + decoder\n",
    "# instantiate autoencoder model\n",
    "autoencoder = Model(inputs,\n",
    "                    decoder(encoder(inputs)),\n",
    "                    name='autoencoder')\n",
    "autoencoder.summary()\n",
    "\n",
    "# Mean Square Error (MSE) loss function, adagrad optimizer\n",
    "autoencoder.compile(loss='mse', optimizer='adagrad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-massachusetts",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"pet_autoencoder.h5\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-wesley",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train the autoencoder\n",
    "autoencoder.fit(pet_feats,\n",
    "                pet_feats,\n",
    "                epochs=10,\n",
    "                batch_size=batch_size,\n",
    "                callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-yeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "pets_decoded = np.zeros((7378, 240, 160, 3))\n",
    "dataset = tf.data.Dataset.from_tensor_slices(pet_feats)\n",
    "dataset = dataset.batch(batch_size=16)\n",
    "x = 0\n",
    "y = 16\n",
    "for i in dataset:\n",
    "    pets_decoded[x:y] = autoencoder.predict_on_batch(i)\n",
    "    x+=i.shape[0]\n",
    "    y+=i.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-portuguese",
   "metadata": {},
   "outputs": [],
   "source": [
    "pets_decoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-spank",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('pets_autoencoder_images', pets_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-addiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rand_images(pet_feats, pets_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-eugene",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.zeros((7378, 240, 160, 6))\n",
    "\n",
    "for i in range(pet_feats.shape[0]):\n",
    "    z[i] = np.dstack((pets_decoded[i], pet_feats[i]))\n",
    "\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.reshape(z, [7378, 38400, 6])\n",
    "\n",
    "labels2 = np.zeros((7378, 38400))\n",
    "kmeans = KMeans(random_state=42, init='k-means++', n_init=10, n_clusters=2, max_iter=1000)\n",
    "for i in range(z.shape[0]):\n",
    "    labels2[i] = kmeans.fit_predict(z[i])\n",
    "    if i % 500 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-variation",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('pets_kmeans2', labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rand_images(pet_feats, labels2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-violence",
   "metadata": {},
   "source": [
    "## Self-organizing maps, Autoencoder, KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-accuracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_with_SOM(image, nx, ny, sigma=1., n=1500):\n",
    "    \n",
    "    pixels = np.reshape(image, (image.shape[0]*image.shape[1], 3))\n",
    "    \n",
    "    som = MiniSom(x=nx, y=ny, input_len=3, sigma=sigma, learning_rate=0.2)\n",
    "    som.random_weights_init(pixels)\n",
    "    starting_weights = som.get_weights().copy()\n",
    "    som.train_random(pixels, n)\n",
    "    \n",
    "    qnt = som.quantization(pixels)\n",
    "    \n",
    "    clustered = np.zeros(image.shape)\n",
    "    \n",
    "    for i,q in enumerate(qnt):\n",
    "        clustered[np.unravel_index(i, shape=(image.shape[0], image.shape[1]))] = q\n",
    "    \n",
    "    final_weights= som.get_weights()\n",
    "    \n",
    "    return clustered, starting_weights, final_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-studio",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.zeros((7378, 240, 160, 3))\n",
    "for i in range(pet_feats.shape[0]):\n",
    "    c[i], _, _ = segment_with_SOM(pet_feats[i], 1, 3, .1)\n",
    "    if i % 500 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-discipline",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('pet_som', c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-allah",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rand_images(pet_feats, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-charles",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.zeros((7378, 240, 160, 9))\n",
    "\n",
    "for i in range(z.shape[0]):\n",
    "    z[i] = np.dstack((pets_decoded[i], pet_feats[i], c[i]))\n",
    "\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-gregory",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.reshape(z, [7378, 38400, 9])\n",
    "\n",
    "labels3 = np.zeros((7378, 38400))\n",
    "kmeans = KMeans(random_state=42, init='random', n_init=10, n_clusters=2, max_iter=1000)\n",
    "for i in range(z.shape[0]):\n",
    "    labels3[i] = kmeans.fit_predict(z[i])\n",
    "    if i % 500 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-hebrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save kmeans images \n",
    "np.save('pets_kmeans3', labels3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-liberty",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rand_images(pet_feats, labels3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-trout",
   "metadata": {},
   "source": [
    "## All features of pets dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-track",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment out if data already loaded\n",
    "pets, pet_auto, pet_som = np.load('pets.npy'), np.load('pets_autoencoder_images.npy'), np.load('pet_som.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Can't load this many images into memory at once so only going to use first 1000\n",
    "\n",
    "hsv = np.zeros((1000, 240, 160, 3))\n",
    "lab = np.zeros((1000, 240, 160, 3))\n",
    "\n",
    "for i in range(1000):\n",
    "    hsv[i] = rgb2hsv(pets[i])\n",
    "    lab[i] = rgb2lab(pets[i])\n",
    "\n",
    "# load all features into one numpy array\n",
    "z = np.zeros((1000, 240, 160, 15))\n",
    "\n",
    "for i in range(1000):\n",
    "    z[i] = np.dstack((pets[i], pet_auto[i], pet_som[i], hsv[i], lab[i]))\n",
    "\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-percentage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape and run k-means\n",
    "\n",
    "z = np.reshape(z, [1000, 38400, 15])\n",
    "\n",
    "labels4 = np.zeros((1000, 38400))\n",
    "kmeans = KMeans(random_state=42, init='random', n_init=10, n_clusters=2, max_iter=1000)\n",
    "for i in range(z.shape[0]):\n",
    "    labels4[i] = kmeans.fit_predict(z[i])\n",
    "    if i % 250 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-direction",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rand_images(pets, labels4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-management",
   "metadata": {},
   "source": [
    "# Drone Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "drone_dir1 = './original_images/'\n",
    "drone_df = pd.DataFrame(columns=['img', 'img_mask'])\n",
    "\n",
    "# load drone image data \n",
    "k = 0\n",
    "for filename in sorted(os.listdir(drone_dir1)):\n",
    "    if filename.endswith('.jpg'):\n",
    "        drone_df.loc[k, 'img'] = np.asarray(Image.open(drone_dir1 + filename).resize((384, 576)))\n",
    "    else:\n",
    "        continue\n",
    "    k = k+1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-sierra",
   "metadata": {},
   "outputs": [],
   "source": [
    "drone_dir2 = './label_images_semantic/'\n",
    "\n",
    "# load mask data\n",
    "k=0\n",
    "for filename in sorted(os.listdir(drone_dir2)):\n",
    "    if filename.endswith('.png'):\n",
    "        drone_df.loc[k, 'img_mask'] = np.asarray(Image.open(drone_dir2 + filename).resize((384, 576)))\n",
    "    else:\n",
    "        continue\n",
    "    k = k+1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-luxembourg",
   "metadata": {},
   "outputs": [],
   "source": [
    "drone, drone_mask = drone_df['img'].to_numpy(), drone_df['img_mask'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-template",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(drone.shape[0]):\n",
    "    if drone[i].shape != (576, 384, 3):\n",
    "        print(i, drone[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-vitamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rand_images(drone, drone_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = []\n",
    "for i in drone:\n",
    "    f.append(i)\n",
    "drone_feats = np.asarray(f)\n",
    "drone_feats = np.reshape(drone_feats, [-1, 576, 384, 3])\n",
    "drone_feats = drone_feats.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-authorization",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('drone_feats', drone_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-craps",
   "metadata": {},
   "source": [
    "## KMeans Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "drone_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-temperature",
   "metadata": {},
   "outputs": [],
   "source": [
    "drone_hsv = np.zeros((400, 576, 384, 3))\n",
    "drone_lab = np.zeros((400, 576, 384, 3))\n",
    "\n",
    "for i in range(drone_feats.shape[0]):\n",
    "    drone_hsv[i] = rgb2hsv(drone_feats[i])\n",
    "    drone_lab[i] = rgb2lab(drone_feats[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-trauma",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(0, drone_feats.shape[0], 8)\n",
    "images = []\n",
    "for ind in idx:\n",
    "    images.append(drone_feats[ind])\n",
    "    images.append(drone_hsv[ind])\n",
    "    images.append(drone_lab[ind])\n",
    "    \n",
    "plt.figure(figsize=(64, 64))\n",
    "num_images = 24\n",
    "rows = 4\n",
    "for i in range(num_images):\n",
    "    plt.subplot(rows+1, rows+1, i+1)\n",
    "    plt.imshow(images[i])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-interstate",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_z = np.zeros((400, 576, 384, 9))\n",
    "\n",
    "for i in range(d_z.shape[0]):\n",
    "    d_z[i] = np.dstack((drone_feats[i], drone_hsv[i], drone_lab[i]))\n",
    "    \n",
    "d_z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-audit",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_z = np.reshape(d_z, [400, 221184, 9])\n",
    "\n",
    "d_z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-defense",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_labels1 = np.zeros((400, 221184))\n",
    "for i in range(d_z.shape[0]):\n",
    "    for j in drone_mask[i]:\n",
    "        c = Counter(j)\n",
    "    kmeans = KMeans(random_state=42, init='random', n_clusters=len(c.keys()), max_iter=1000)\n",
    "    d_labels1[i] = kmeans.fit_predict(d_z[i])\n",
    "    if i % 50 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_labels1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-killer",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_labels1 = np.reshape(d_labels1, [-1, 576, 384])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-blond",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('drone_kmeans1', d_labels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-zealand",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rand_images(drone_feats, d_labels1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-robin",
   "metadata": {},
   "source": [
    "## Autoencoder and KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-programming",
   "metadata": {},
   "outputs": [],
   "source": [
    "drone_feats = np.reshape(drone_feats, [-1, 576, 384, 3])\n",
    "drone_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-mexico",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network parameters\n",
    "input_shape = (576, 384, 3)\n",
    "batch_size = 1\n",
    "kernel_size = 3\n",
    "latent_dim = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-glance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder/decoder number of CNN layers and filters per layer\n",
    "layer_filters = [16, 32, 64, 128, 256, 512]\n",
    "\n",
    "# first build the encoder model\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = inputs\n",
    "for filters in layer_filters:\n",
    "    x = Conv2D(filters=filters,\n",
    "               kernel_size=kernel_size,\n",
    "               activation='relu',\n",
    "               kernel_initializer = 'he_normal',\n",
    "               strides=1,\n",
    "               padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "shape = K.int_shape(x)\n",
    "\n",
    "# generate latent vector\n",
    "x = Flatten()(x)\n",
    "latent = Dense(latent_dim, name='latent_vector')(x)\n",
    "\n",
    "# instantiate encoder model\n",
    "encoder = Model(inputs,\n",
    "                latent,\n",
    "                name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-estate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the decoder model\n",
    "latent_inputs = Input(shape=(latent_dim,), name='decoder_input')\n",
    "\n",
    "x = Dense(shape[1] * shape[2] * shape[3])(latent_inputs)\n",
    "x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
    "\n",
    "# stack of Conv2DTranspose(64)-Conv2DTranspose(32)\n",
    "for filters in layer_filters[::-1]:\n",
    "    x = Conv2DTranspose(filters=filters,\n",
    "                        kernel_size=kernel_size,\n",
    "                        activation='relu',\n",
    "                        kernel_initializer = 'he_normal',\n",
    "                        strides=2,\n",
    "                        padding='same')(x)\n",
    "\n",
    "# reconstruct the input\n",
    "outputs = Conv2DTranspose(filters=3,\n",
    "                          kernel_size=1,\n",
    "                          activation='sigmoid',\n",
    "                          padding='same',\n",
    "                          kernel_initializer = 'he_normal',\n",
    "                          name='decoder_output')(x)\n",
    "\n",
    "# instantiate decoder model\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-monitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder = encoder + decoder\n",
    "# instantiate autoencoder model\n",
    "autoencoder = Model(inputs,\n",
    "                    decoder(encoder(inputs)),\n",
    "                    name='autoencoder')\n",
    "autoencoder.summary()\n",
    "\n",
    "# Mean Square Error (MSE) loss function, adagrad optimizer\n",
    "autoencoder.compile(loss='mse', optimizer='adagrad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"drone_autoencoder.h5\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-partner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the autoencoder\n",
    "autoencoder.fit(drone_feats,\n",
    "                drone_feats,\n",
    "                epochs=100,\n",
    "                batch_size=batch_size,\n",
    "                callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-hearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "drone_decoded = np.zeros((400, 576, 384, 3))\n",
    "dataset = tf.data.Dataset.from_tensor_slices(drone_feats)\n",
    "dataset = dataset.batch(batch_size=1)\n",
    "x = 0\n",
    "y = 1\n",
    "for i in dataset:\n",
    "    drone_decoded[x:y] = autoencoder.predict_on_batch(i)\n",
    "    x+=i.shape[0]\n",
    "    y+=i.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-better",
   "metadata": {},
   "outputs": [],
   "source": [
    "drone_decoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('drone_autoencoder_images', drone_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-appearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rand_images(drone_feats, drone_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-trance",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_z2 = np.zeros((400, 576, 384, 6))\n",
    "\n",
    "for i in range(drone_feats.shape[0]):\n",
    "    d_z2[i] = np.dstack((drone_decoded[i], drone_feats[i]))\n",
    "\n",
    "d_z2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-watershed",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_z2 = np.reshape(d_z2, [400, 221184, 6])\n",
    "\n",
    "d_z2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-auditor",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_labels2 = np.zeros((400, 221184))\n",
    "\n",
    "kmeans = KMeans(random_state=42, init='random', n_clusters=5, max_iter=1000)\n",
    "for i in range(d_z2.shape[0]):\n",
    "    d_labels2[i] = kmeans.fit_predict(d_z2[i])\n",
    "    if i % 50 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-australia",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('drone_kmeans2', d_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rand_images(drone_feats, d_labels2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-confidentiality",
   "metadata": {},
   "source": [
    "## Self-organizing Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "drone_feats = np.load('drone_feats.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-finnish",
   "metadata": {},
   "outputs": [],
   "source": [
    "drone_decoded = np.load('drone_autoencoder_images.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_maps = np.zeros((400, 576, 384, 3))\n",
    "for i in range(drone_feats.shape[0]):\n",
    "    d_maps[i], _, _ = segment_with_SOM(drone_feats[i], 1, 5, .1)\n",
    "    if i % 50 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-greek",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(d_maps[157])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-observer",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_z3 = np.zeros((400, 576, 384, 9))\n",
    "\n",
    "for i in range(d_z3.shape[0]):\n",
    "    d_z3[i] = np.dstack((drone_decoded[i], drone_feats[i], d_maps[i]))\n",
    "\n",
    "d_z3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-infection",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_z3 = np.reshape(d_z3, [400, 221184, 9])\n",
    "\n",
    "d_labels3 = np.zeros((400, 221184))\n",
    "for i in range(d_z3.shape[0]):\n",
    "    kmeans = KMeans(random_state=42, init='k-means++', n_init=10, n_clusters=5, max_iter=1000)\n",
    "    d_labels3[i] = kmeans.fit_predict(d_z3[i])\n",
    "    if i % 50 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-exhibition",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_labels3 = np.reshape(d_labels3, [-1, 576, 384])\n",
    "\n",
    "np.save('drone_kmeans3', d_labels3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rand_images(drone_feats, d_labels3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-cliff",
   "metadata": {},
   "source": [
    "## All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all features into array\n",
    "d_z4 = np.zeros((400, 576, 384, 15))\n",
    "\n",
    "for i in range(d_z4.shape[0]):\n",
    "    d_z4[i] = np.dstack((drone_decoded[i], drone_feats[i], d_maps[i], drone_hsv[i], drone_lab[i]))\n",
    "\n",
    "d_z4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-smoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape and run kmeans\n",
    "d_z4 = np.reshape(d_z4, [400, 221184, 15])\n",
    "\n",
    "d_labels4 = np.zeros((400, 221184))\n",
    "for i in range(d_z4.shape[0]):\n",
    "    kmeans = KMeans(random_state=42, init='k-means++', n_init=10, n_clusters=5, max_iter=1000)\n",
    "    d_labels4[i] = kmeans.fit_predict(d_z4[i])\n",
    "    if i % 50 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape and save kmeans\n",
    "d_labels4 = np.reshape(d_labels4, [-1, 576, 384])\n",
    "\n",
    "np.save('drone_kmeans4', d_labels4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-twist",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rand_images(drone_feats, d_labels4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-needle",
   "metadata": {},
   "source": [
    "## Try 5 original images for kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment out if data loaded \n",
    "drone_feats = np.load('drone_feats.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 5 copies of each image\n",
    "d_z5 = np.zeros((400, 576, 384, 15))\n",
    "\n",
    "for i in range(d_z5.shape[0]):\n",
    "    d_z5[i] = np.dstack((drone_feats[i], drone_feats[i], drone_feats[i], drone_feats[i], drone_feats[i]))\n",
    "\n",
    "d_z5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-preliminary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape and run kmeans\n",
    "d_z5 = np.reshape(d_z5, [400, 221184, 15])\n",
    "\n",
    "d_labels5 = np.zeros((400, 221184))\n",
    "for i in range(d_z5.shape[0]):\n",
    "    kmeans = KMeans(random_state=42, init='k-means++', n_init=10, n_clusters=5, max_iter=1000)\n",
    "    d_labels5[i] = kmeans.fit_predict(d_z5[i])\n",
    "    if i % 50 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-bargain",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rand_images(drone_feats, d_labels5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-california",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
